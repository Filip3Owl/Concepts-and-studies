{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93b3de8f",
   "metadata": {},
   "source": [
    "# Implementing TF-IDF in Python with nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc3c514",
   "metadata": {},
   "source": [
    "To implement **TF-IDF in Python**, you typically follow a few core steps. First, you need to **preprocess your text documents**, which includes essential techniques like tokenization, stopword removal, and stemming. After preprocessing, you can calculate the TF-IDF scores using `TfidfVectorizer` from `sklearn.feature_extraction.text`. This class efficiently transforms your documents into **TF-IDF feature vectors**, which are then ready for subsequent text analysis tasks such as classification or clustering.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e55e2efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document: I love to play soccer\n",
      "  love: 0.5385\n",
      "  play: 0.5385\n",
      "  soccer: 0.3606\n",
      "  to: 0.5385\n",
      "\n",
      "Document: Soccer is my favorite sport\n",
      "  favorite: 0.5422\n",
      "  is: 0.4375\n",
      "  my: 0.4375\n",
      "  soccer: 0.3631\n",
      "  sport: 0.4375\n",
      "\n",
      "Document: I enjoy playing soccer with my friends\n",
      "  enjoy: 0.4428\n",
      "  friends: 0.4428\n",
      "  my: 0.3573\n",
      "  playing: 0.4428\n",
      "  soccer: 0.2966\n",
      "  with: 0.4428\n",
      "\n",
      "Document: Football is another popular sport\n",
      "  another: 0.4821\n",
      "  football: 0.4821\n",
      "  is: 0.3890\n",
      "  popular: 0.4821\n",
      "  sport: 0.3890\n",
      "\n",
      "Document: I don't like basketball\n",
      "  basketball: 0.5774\n",
      "  don: 0.5774\n",
      "  like: 0.5774\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk # Imports the Natural Language Toolkit library.\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # Imports TfidfVectorizer for converting text to TF-IDF features.\n",
    "\n",
    "# Sample documents for demonstration.\n",
    "sample_documents = [\n",
    "    \"I love to play soccer\",\n",
    "    \"Soccer is my favorite sport\",\n",
    "    \"I enjoy playing soccer with my friends\",\n",
    "    \"Football is another popular sport\",\n",
    "    \"I don't like basketball\"\n",
    "]\n",
    "\n",
    "# Create the TF-IDF vectorizer object.\n",
    "# This object will learn the vocabulary and IDF values from the documents,\n",
    "# and then transform the documents into TF-IDF numerical representations.\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Compute the TF-IDF scores for the sample documents.\n",
    "# 'fit_transform' first learns the vocabulary and IDF values from 'sample_documents',\n",
    "# then transforms these documents into a sparse matrix of TF-IDF scores.\n",
    "tfidf_scores_matrix = tfidf_vectorizer.fit_transform(sample_documents)\n",
    "\n",
    "# Get the names of the features (terms) from the vectorizer's learned vocabulary.\n",
    "# These correspond to the columns in the TF-IDF matrix.\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Print the TF-IDF scores for each document.\n",
    "# 'enumerate' is used to get both the index (i) and the document content (doc).\n",
    "for i, doc in enumerate(sample_documents):\n",
    "    print(\"Document:\", doc) # Print the original document text.\n",
    "    # 'enumerate' is used again to get the index (j) and the term (feature_name).\n",
    "    for j, term in enumerate(feature_names):\n",
    "        # Access the TF-IDF score for the current document (i) and current term (j).\n",
    "        score = tfidf_scores_matrix[i, j]\n",
    "        # Only print terms that have a non-zero TF-IDF score in the current document.\n",
    "        if score > 0:\n",
    "            print(f\"  {term}: {score:.4f}\") # Format score to 4 decimal places for readability.\n",
    "    print() # Print an empty line for better separation between document outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2cb01a",
   "metadata": {},
   "source": [
    "---\n",
    "**TF-IDF scores** provide valuable insights into a term's importance within a document corpus. Understanding how to interpret these scores is key for various text mining and information retrieval tasks.\n",
    "\n",
    "**High TF-IDF scores** indicate a term is **frequent in a specific document** but **relatively rare across the entire corpus**. This suggests the term is highly **distinctive and significant** to that particular document's content.\n",
    "\n",
    "Conversely, **low TF-IDF scores** mean a term is **infrequent in a document** or **very common throughout the corpus**. These terms are typically less informative and contribute little to the unique understanding of a specific document (e.g., common words like \"the,\" \"and,\" or \"is\").\n",
    "\n",
    "Interpreting TF-IDF also involves **comparing scores** across different terms and documents. By examining scores within a single document, we can identify its most differentiating terms. Comparing scores across different documents helps pinpoint terms that are highly relevant or characteristic of specific documents or topics. This analysis is crucial for tasks like document clustering, topic modeling, and information retrieval, aiding in the identification and extraction of key textual information.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb83740",
   "metadata": {},
   "source": [
    "### TF-IDF: Information Retrieval's Core\n",
    "\n",
    "**TF-IDF** stands as a fundamental technique in **information retrieval (IR)**, pivotal for **ranking and retrieving relevant documents** in response to user queries. Search engines widely employ TF-IDF scores to effectively match query terms with document content, thereby delivering more precise search outcomes.\n",
    "\n",
    "Its primary applications within IR include:\n",
    "\n",
    "* **Document Ranking:** TF-IDF is instrumental in assessing a document's relevance to a given query. Documents with higher TF-IDF scores for the query's terms are prioritized and ranked higher in search results, ensuring users access the most pertinent information.\n",
    "* **Keyword Extraction:** The technique is highly effective at identifying **key terms or phrases** within documents by pinpointing those with elevated TF-IDF scores. These distinctive words are crucial assets for tasks like document indexing, categorization, and topic labeling.\n",
    "\n",
    "Ultimately, the inherent adaptability of TF-IDF significantly enhances capabilities in document ranking, keyword extraction, and overall information retrieval efficiency.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2994689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\tWord: document, TF-IDF Score: 0.4698\n",
      "\tWord: first, TF-IDF Score: 0.5803\n",
      "\tWord: is, TF-IDF Score: 0.3841\n",
      "\tWord: the, TF-IDF Score: 0.3841\n",
      "\tWord: this, TF-IDF Score: 0.3841\n",
      "\n",
      "Document 2:\n",
      "\tWord: document, TF-IDF Score: 0.6876\n",
      "\tWord: is, TF-IDF Score: 0.2811\n",
      "\tWord: second, TF-IDF Score: 0.5386\n",
      "\tWord: the, TF-IDF Score: 0.2811\n",
      "\tWord: this, TF-IDF Score: 0.2811\n",
      "\n",
      "Document 3:\n",
      "\tWord: and, TF-IDF Score: 0.5958\n",
      "\tWord: is, TF-IDF Score: 0.3109\n",
      "\tWord: the, TF-IDF Score: 0.3109\n",
      "\tWord: third, TF-IDF Score: 0.5958\n",
      "\tWord: this, TF-IDF Score: 0.3109\n",
      "\n",
      "Document 4:\n",
      "\tWord: document, TF-IDF Score: 0.4698\n",
      "\tWord: first, TF-IDF Score: 0.5803\n",
      "\tWord: is, TF-IDF Score: 0.3841\n",
      "\tWord: the, TF-IDF Score: 0.3841\n",
      "\tWord: this, TF-IDF Score: 0.3841\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk # Imports the Natural Language Toolkit library.\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # Imports TfidfVectorizer to convert text to TF-IDF features.\n",
    "\n",
    "# Sample documents for demonstration.a\n",
    "documents = [\n",
    "    \"This is the first document.\",\n",
    "    \"This document is the second document.\",\n",
    "    \"And this is the third.\",\n",
    "    \"This is the first document?\"\n",
    "]\n",
    "\n",
    "# Preprocess the documents.\n",
    "# Each document is tokenized (split into words) after being converted to lowercase.\n",
    "processed_corpus = [nltk.word_tokenize(document.lower()) for document in documents]\n",
    "# Convert the preprocessed documents (list of tokens) back into strings, joined by spaces.\n",
    "processed_corpus = [' '.join(doc_tokens) for doc_tokens in processed_corpus]\n",
    "\n",
    "# Create the TF-IDF vectorizer.\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Compute the TF-IDF scores.\n",
    "# 'fit_transform' learns the vocabulary and IDF values from the 'processed_corpus',\n",
    "# then transforms these documents into a sparse matrix of TF-IDF scores.\n",
    "tfidf_scores_matrix = tfidf_vectorizer.fit_transform(processed_corpus)\n",
    "\n",
    "# Get the names of the features (words) from the vectorizer's learned vocabulary.\n",
    "# These correspond to the columns in the TF-IDF matrix.\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Print the TF-IDF scores for each document.\n",
    "# 'enumerate' is used to get both the document index and its corresponding scores.\n",
    "# '.toarray()' converts the sparse matrix row to a dense NumPy array for easier iteration.\n",
    "for doc_index, doc_scores in enumerate(tfidf_scores_matrix.toarray()):\n",
    "    print(f\"Document {doc_index + 1}:\") # Print the document number.\n",
    "    # 'enumerate' is used again to get the word index and its score within the current document.\n",
    "    for word_index, score in enumerate(doc_scores):\n",
    "        # Only print terms that have a non-zero TF-IDF score in the current document.\n",
    "        if score > 0:\n",
    "            # Print the word (feature_name) and its TF-IDF score, formatted to 4 decimal places.\n",
    "            print(f\"\\tWord: {feature_names[word_index]}, TF-IDF Score: {score:.4f}\")\n",
    "    print() # Print an empty line for better separation between document outputs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
