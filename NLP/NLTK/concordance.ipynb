{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d1a63c3",
   "metadata": {},
   "source": [
    "# Working with texts\n",
    "\n",
    "There are several ways to analyze the context of a text besides simply reading it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32e0931f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd90fd2c",
   "metadata": {},
   "source": [
    "Let's analyze the context of a word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f420b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 11 of 11 matches:\n",
      "ong the former , one was of a most monstrous size . ... This came towards us , \n",
      "ON OF THE PSALMS . \" Touching that monstrous bulk of the whale or ork we have r\n",
      "ll over with a heathenish array of monstrous clubs and spears . Some were thick\n",
      "d as you gazed , and wondered what monstrous cannibal and savage could ever hav\n",
      "that has survived the flood ; most monstrous and most mountainous ! That Himmal\n",
      "they might scout at Moby Dick as a monstrous fable , or still worse and more de\n",
      "th of Radney .'\" CHAPTER 55 Of the Monstrous Pictures of Whales . I shall ere l\n",
      "ing Scenes . In connexion with the monstrous pictures of whales , I am strongly\n",
      "ere to enter upon those still more monstrous stories of them which are to be fo\n",
      "ght have been rummaged out of this monstrous cabinet there is no telling . But \n",
      "of Whale - Bones ; for Whales of a monstrous size are oftentimes cast up dead u\n"
     ]
    }
   ],
   "source": [
    "text1.concordance(\"monstrous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89c4bb35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 11 of 11 matches:\n",
      ". \" Now , Palmer , you shall see a monstrous pretty girl .\" He immediately went\n",
      "your sister is to marry him . I am monstrous glad of it , for then I shall have\n",
      "ou may tell your sister . She is a monstrous lucky girl to get him , upon my ho\n",
      "k how you will like them . Lucy is monstrous pretty , and so good humoured and \n",
      " Jennings , \" I am sure I shall be monstrous glad of Miss Marianne ' s company \n",
      " usual noisy cheerfulness , \" I am monstrous glad to see you -- sorry I could n\n",
      "t however , as it turns out , I am monstrous glad there was never any thing in \n",
      "so scornfully ! for they say he is monstrous fond of her , as well he may . I s\n",
      "possible that she should .\" \" I am monstrous glad of it . Good gracious ! I hav\n",
      "thing of the kind . So then he was monstrous happy , and talked on some time ab\n",
      "e very genteel people . He makes a monstrous deal of money , and they keep thei\n"
     ]
    }
   ],
   "source": [
    "text2.concordance(\"monstrous\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c977900c",
   "metadata": {},
   "source": [
    "The same words have different contexts in different texts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7865bff",
   "metadata": {},
   "source": [
    "We can measure the similarity of any word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "367624c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true contemptible christian abundant few part mean careful puzzled\n",
      "mystifying passing curious loving wise doleful gamesome singular\n",
      "delightfully perilous fearless\n",
      "very so exceedingly heartily a as good great extremely remarkably\n",
      "sweet vast amazingly\n"
     ]
    }
   ],
   "source": [
    "text1.similar(\"monstrous\")\n",
    "text2.similar(\"monstrous\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81519b5a",
   "metadata": {},
   "source": [
    "In question, the context *differ*. Therefore, we extract valuable information with just a few lines of code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dd1b40",
   "metadata": {},
   "source": [
    "Furthermore, we can analyze the relationship between two words in a given context. We must use **common_contexts()**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3a10f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No common contexts were found\n",
      "am_glad a_pretty a_lucky is_pretty be_glad\n"
     ]
    }
   ],
   "source": [
    "text1.common_contexts([\"monstrous\", \"very\"])\n",
    "text2.common_contexts([\"monstrous\", \"very\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7526b246",
   "metadata": {},
   "source": [
    "## Ocurrence of words in a text\n",
    "\n",
    "Through the occurence of words in text we can determine many things, such as word trend analyses, assosiation between terms and even to train algorithms as a means of data preparation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20382bbd",
   "metadata": {},
   "source": [
    "First we must find out the length of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e60742a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44764\n"
     ]
    }
   ],
   "source": [
    "print(len(text3))\n",
    "#Tokenization process.\n",
    "tokens = sorted(set(text3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2613cd2",
   "metadata": {},
   "source": [
    "We can use the FreqDist() object to **count the frequencies** of tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee1e4f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 2789 samples and 2789 outcomes>\n",
      "[('!', 1), (\"'\", 1), ('(', 1), (')', 1), (',', 1), (',)', 1), ('.', 1), ('.)', 1), (':', 1), (';', 1), (';)', 1), ('?', 1), ('?)', 1), ('A', 1), ('Abel', 1), ('Abelmizraim', 1), ('Abidah', 1), ('Abide', 1), ('Abimael', 1), ('Abimelech', 1)]\n"
     ]
    }
   ],
   "source": [
    "fdist = FreqDist(tokens)\n",
    "print(fdist)\n",
    "#We can return the most frequent tokens.\n",
    "most_common = fdist.most_common(20)\n",
    "print(most_common)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca6885b",
   "metadata": {},
   "source": [
    "We should note that although we have 44.764 elements in the text when **tokenized**, only 2.789 unique items remain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d5d0bd",
   "metadata": {},
   "source": [
    "Another important thing is to measure the lexical richness of the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16f9ee0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06230453042623537\n"
     ]
    }
   ],
   "source": [
    "def lexical_diversity(text):\n",
    "    return len(set(text)) / len(text)\n",
    "\n",
    "print(lexical_diversity(text3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ea29b7",
   "metadata": {},
   "source": [
    "We also measure the **percentage of occurance** of a given word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "046a3202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002233937985881512\n"
     ]
    }
   ],
   "source": [
    "def percentage(count, total):\n",
    "    return 100 * count / total\n",
    "\n",
    "print(percentage(fdist[\"smote\"], len(text3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a25f54",
   "metadata": {},
   "source": [
    "## corpus.gutenberg.fileids() in NLTK\n",
    "\n",
    "The corpus.gutenberg.fileids() function is part of the Natural Language Toolkit (NLTK) library in Python. It provides access to a list of available text file identifiers (file IDs) in the Gutenberg corpus, which is a small collection of literary texts included with NLTK.\n",
    "\n",
    "### Purpose\n",
    "\n",
    "This function is used to list all the file names (as strings) of the texts available in the gutenberg corpus. These file IDs can then be used to load and analyze specific texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "185f42f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.corpus.gutenberg.fileids()\n",
    "\n",
    "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt',\n",
    " 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt',\n",
    " 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt',\n",
    " 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt',\n",
    " 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt',\n",
    " 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bcd9f7",
   "metadata": {},
   "source": [
    "Now I will choose the first text from these options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "64339131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192427"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emma = nltk.corpus.gutenberg.words('austen-emma.txt')\n",
    "\n",
    "len(emma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a5d041",
   "metadata": {},
   "source": [
    "We don't need to type such long names all the time. Python provides another version of the import statement, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "afba9160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', Ellipsis]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "\n",
    "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt',...]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581c4dca",
   "metadata": {},
   "source": [
    "Now let's write a short program to display further information about each text by looping through all the fileid values ​​corresponding to the previously identified gutenberg file identifiers and then calculating exstatistics for each text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "81187899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "austen-emma.txt\n",
      " - Caracteres: 887071\n",
      " - Palavras:   192427\n",
      " - Frases:     7752\n",
      " - Vocabulário único: 7344\n",
      "----------------------------------------\n",
      "austen-persuasion.txt\n",
      " - Caracteres: 466292\n",
      " - Palavras:   98171\n",
      " - Frases:     3747\n",
      " - Vocabulário único: 5835\n",
      "----------------------------------------\n",
      "austen-sense.txt\n",
      " - Caracteres: 673022\n",
      " - Palavras:   141576\n",
      " - Frases:     4999\n",
      " - Vocabulário único: 6403\n",
      "----------------------------------------\n",
      "bible-kjv.txt\n",
      " - Caracteres: 4332554\n",
      " - Palavras:   1010654\n",
      " - Frases:     30103\n",
      " - Vocabulário único: 12767\n",
      "----------------------------------------\n",
      "blake-poems.txt\n",
      " - Caracteres: 38153\n",
      " - Palavras:   8354\n",
      " - Frases:     438\n",
      " - Vocabulário único: 1535\n",
      "----------------------------------------\n",
      "bryant-stories.txt\n",
      " - Caracteres: 249439\n",
      " - Palavras:   55563\n",
      " - Frases:     2863\n",
      " - Vocabulário único: 3940\n",
      "----------------------------------------\n",
      "burgess-busterbrown.txt\n",
      " - Caracteres: 84663\n",
      " - Palavras:   18963\n",
      " - Frases:     1054\n",
      " - Vocabulário único: 1559\n",
      "----------------------------------------\n",
      "carroll-alice.txt\n",
      " - Caracteres: 144395\n",
      " - Palavras:   34110\n",
      " - Frases:     1703\n",
      " - Vocabulário único: 2636\n",
      "----------------------------------------\n",
      "chesterton-ball.txt\n",
      " - Caracteres: 457450\n",
      " - Palavras:   96996\n",
      " - Frases:     4779\n",
      " - Vocabulário único: 8335\n",
      "----------------------------------------\n",
      "chesterton-brown.txt\n",
      " - Caracteres: 406629\n",
      " - Palavras:   86063\n",
      " - Frases:     3806\n",
      " - Vocabulário único: 7794\n",
      "----------------------------------------\n",
      "chesterton-thursday.txt\n",
      " - Caracteres: 320525\n",
      " - Palavras:   69213\n",
      " - Frases:     3742\n",
      " - Vocabulário único: 6349\n",
      "----------------------------------------\n",
      "edgeworth-parents.txt\n",
      " - Caracteres: 935158\n",
      " - Palavras:   210663\n",
      " - Frases:     10230\n",
      " - Vocabulário único: 8447\n",
      "----------------------------------------\n",
      "melville-moby_dick.txt\n",
      " - Caracteres: 1242990\n",
      " - Palavras:   260819\n",
      " - Frases:     10059\n",
      " - Vocabulário único: 17231\n",
      "----------------------------------------\n",
      "milton-paradise.txt\n",
      " - Caracteres: 468220\n",
      " - Palavras:   96825\n",
      " - Frases:     1851\n",
      " - Vocabulário único: 9021\n",
      "----------------------------------------\n",
      "shakespeare-caesar.txt\n",
      " - Caracteres: 112310\n",
      " - Palavras:   25833\n",
      " - Frases:     2163\n",
      " - Vocabulário único: 3032\n",
      "----------------------------------------\n",
      "shakespeare-hamlet.txt\n",
      " - Caracteres: 162881\n",
      " - Palavras:   37360\n",
      " - Frases:     3106\n",
      " - Vocabulário único: 4716\n",
      "----------------------------------------\n",
      "shakespeare-macbeth.txt\n",
      " - Caracteres: 100351\n",
      " - Palavras:   23140\n",
      " - Frases:     1907\n",
      " - Vocabulário único: 3464\n",
      "----------------------------------------\n",
      "whitman-leaves.txt\n",
      " - Caracteres: 711215\n",
      " - Palavras:   154883\n",
      " - Frases:     4250\n",
      " - Vocabulário único: 12452\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "\n",
    "for fileid in gutenberg.fileids():\n",
    "    num_chars = len(gutenberg.raw(fileid))  # Corrigido: removeu o [1]\n",
    "    num_words = len(gutenberg.words(fileid))\n",
    "    num_sents = len(gutenberg.sents(fileid))\n",
    "    num_vocab = len(set(w.lower() for w in gutenberg.words(fileid)))\n",
    "\n",
    "    print(f\"{fileid}\")\n",
    "    print(f\" - Caracteres: {num_chars}\")\n",
    "    print(f\" - Palavras:   {num_words}\")\n",
    "    print(f\" - Frases:     {num_sents}\")\n",
    "    print(f\" - Vocabulário único: {num_vocab}\")\n",
    "    print(\"-\" * 40)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94612322",
   "metadata": {},
   "source": [
    "## What is a Corpus in NLTK?\n",
    "In the context of NLTK (Natural Language Toolkit), a corpus is a large and structured collection of texts that can be used for various natural language processing (NLP) tasks such as tokenization, tagging, parsing, and language modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f4beba4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11314,)\n",
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
      "From: lerxst@wam.umd.edu (where's my thing)\n",
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n",
      "Organization: University of Maryland, College Park\n",
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "- IL\n",
      "   ---- brought to you by your neighborhood Lerxst ----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# Download the training data\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "\n",
    "# Download the test data\n",
    "newsgroups_test = fetch_20newsgroups(subset='test')\n",
    "\n",
    "# You can then access the data\n",
    "print(newsgroups_train.filenames.shape)\n",
    "print(newsgroups_train.target_names)\n",
    "print(newsgroups_train.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2660867",
   "metadata": {},
   "source": [
    "## Meaning of each part:\n",
    "\n",
    "(11314,)\n",
    "This is likely the index or ID of the document in a dataset — in this case, document number 11314 in the 20 Newsgroups dataset.\n",
    "\n",
    "['alt.atheism', 'comp.graphics', ..., 'talk.religion.misc']\n",
    "These are the 20 newsgroups (topics/categories) in the dataset.\n",
    "\n",
    "This specific post belongs to one of them (e.g., maybe rec.autos in this case, since it's about a car).\n",
    "\n",
    "From: lerxst@wam.umd.edu (where's my thing)\n",
    "The author of the post (username: lerxst) from the University of Maryland.\n",
    "\n",
    "Subject: WHAT car is this!?\n",
    "The title/topic of the post — the author is asking about an unknown car.\n",
    "\n",
    "Nntp-Posting-Host: rac3.wam.umd.edu\n",
    "The server/host that posted it, part of the Usenet infrastructure.\n",
    "\n",
    "Organization: University of Maryland, College Park\n",
    "The user's organization or institution.\n",
    "\n",
    "Lines: 15\n",
    "Number of text lines in the message body.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
