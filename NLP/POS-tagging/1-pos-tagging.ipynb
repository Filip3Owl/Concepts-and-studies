{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa59516b",
   "metadata": {},
   "source": [
    "# POS-TAGGING APLICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1bbbaf",
   "metadata": {},
   "source": [
    "**Part-of-Speech (POS) Tagging** is a fundamental task in Natural Language Processing (NLP) that involves **assigning a grammatical category (or \"tag\") to each word in a given text.**\n",
    "\n",
    "**Objective:** To identify the lexical category of each word, such as noun, verb, adjective, adverb, pronoun, preposition, conjunction, interjection, etc., based on its definition and its context within the sentence.\n",
    "\n",
    "**How it Works:**\n",
    "\n",
    "* **Input:** A sequence of words (a sentence or a chunk of text).\n",
    "* **Output:** A sequence of words, where each word is paired with its corresponding POS tag.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "* **Sentence:** \"The quick brown fox jumps over the lazy dog.\"\n",
    "* **POS Tagged Output:**\n",
    "    * \"The\": Determiner (DT)\n",
    "    * \"quick\": Adjective (JJ)\n",
    "    * \"brown\": Adjective (JJ)\n",
    "    * \"fox\": Noun (NN)\n",
    "    * \"jumps\": Verb (VBZ)\n",
    "    * \"over\": Preposition (IN)\n",
    "    * \"the\": Determiner (DT)\n",
    "    * \"lazy\": Adjective (JJ)\n",
    "    * \"dog\": Noun (NN)\n",
    "\n",
    "**Importance/Applications:**\n",
    "\n",
    "* **Foundation for Higher-Level NLP Tasks:** POS tagging is a crucial preprocessing step for many more complex NLP applications.\n",
    "* **Word Sense Disambiguation:** Helps to understand the correct meaning of a word that might have multiple senses (e.g., \"bank\" as a financial institution vs. \"bank\" as a river bank).\n",
    "* **Syntactic Parsing:** Essential for building parse trees and understanding the grammatical structure of sentences.\n",
    "* **Named Entity Recognition (NER):** Helps to identify proper nouns, locations, organizations, etc.\n",
    "* **Machine Translation:** Provides grammatical information that can guide translation.\n",
    "* **Information Extraction:** Aids in extracting specific data from text.\n",
    "* **Text-to-Speech Systems:** Helps determine pronunciation and intonation (e.g., \"read\" - present vs. past tense).\n",
    "\n",
    "**Challenges:**\n",
    "\n",
    "* **Ambiguity:** Many words can function as different parts of speech depending on the context (e.g., \"book\" as a noun vs. \"book\" as a verb).\n",
    "* **New Words/Slang:** Models need to be robust enough to handle words not seen during training.\n",
    "\n",
    "**Common Approaches:**\n",
    "\n",
    "* **Rule-Based Tagging:** Uses hand-crafted rules based on suffixes, prefixes, and context.\n",
    "* **Stochastic/Statistical Tagging:** Uses probability based on how frequently a word appears with a certain tag and how frequently one tag follows another. (e.g., Hidden Markov Models - HMMs, Maximum Entropy Models).\n",
    "* **Neural Network-Based Tagging:** Uses deep learning models (like RNNs, LSTMs, Transformers) to learn complex patterns from data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c38afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Felipe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Felipe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'),\n",
       " ('will', 'MD'),\n",
       " ('buy', 'VB'),\n",
       " ('ice', 'JJ'),\n",
       " ('cream', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk # Import the Natural Language Toolkit (NLTK) library, which is a powerful tool for working with human language data.\n",
    "\n",
    "# Download the 'averaged_perceptron_tagger' resource. This is a pre-trained statistical model\n",
    "# used by NLTK for Part-of-Speech (POS) tagging. It assigns grammatical categories (like noun, verb, adjective)\n",
    "# to words in a text. This resource needs to be downloaded once to be available for use.\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# Download the 'punkt' tokenizer models. This resource contains pre-trained models for tokenizing\n",
    "# text into sentences and words. Tokenization is the process of breaking down a text into smaller units.\n",
    "# 'punkt' is essential for the `word_tokenize` function used below. This also needs to be downloaded once.\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Define a sample text string.\n",
    "text_sentence = \"I will buy ice cream.\"\n",
    "\n",
    "# Tokenize the text_sentence into individual words. The `nltk.word_tokenize()` function splits the string\n",
    "# into a list of words and punctuation marks.\n",
    "# For example, \"I will buy ice cream.\" becomes ['I', 'will', 'buy', 'ice', 'cream', '.'].\n",
    "words_tokenized = nltk.word_tokenize(text_sentence)\n",
    "\n",
    "# Perform Part-of-Speech (POS) tagging on the tokenized words.\n",
    "# The `nltk.pos_tag()` function takes a list of words and returns a list of tuples,\n",
    "# where each tuple contains a word and its corresponding POS tag.\n",
    "# For example, ['I', 'will', 'buy', 'ice', 'cream', '.'] might become\n",
    "# [('I', 'PRP'), ('will', 'MD'), ('buy', 'VB'), ('ice', 'NN'), ('cream', 'NN'), ('.', '.')]\n",
    "# (PRP: Personal Pronoun, MD: Modal Verb, VB: Verb Base Form, NN: Noun, .: Punctuation mark)\n",
    "pos_tagged_words = nltk.pos_tag(words_tokenized)\n",
    "\n",
    "# The result of `nltk.pos_tag(text)` will be a list of tuples, which would typically be printed\n",
    "# or used for further NLP tasks.\n",
    "print(pos_tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d70708e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('They', 'PROPN'), ('are', 'PROPN'), ('solving', 'PROPN'), ('a', 'PRON'), ('mystery', 'VERB'), ('!', 'PUNCT')]\n"
     ]
    }
   ],
   "source": [
    "#python -m spacy download pt_core_news_sm\n",
    "\n",
    "# Import the spaCy library, which is an open-source library for advanced Natural Language Processing (NLP) in Python.\n",
    "# spaCy is known for its efficiency, speed, and production-ready NLP models.\n",
    "import spacy \n",
    "\n",
    "# Load a pre-trained spaCy language model for Portuguese.\n",
    "# 'pt_core_news_sm' refers to a small (sm) Portuguese (pt) model trained on news text (core_news).\n",
    "# This model includes components for tokenization, POS tagging, dependency parsing, named entity recognition (NER), etc.\n",
    "# The loaded model object, assigned to the variable 'PLN', is essentially the \"pipeline\" for processing Portuguese text.\n",
    "nlp_pipeline_pt = spacy.load('pt_core_news_sm')\n",
    "\n",
    "# Process a given text string using the loaded spaCy model.\n",
    "# When a string is passed to the nlp_pipeline_pt object, spaCy processes it through its various components\n",
    "# (tokenizer, tagger, parser, etc.) and returns a 'Doc' object.\n",
    "# The 'Doc' object is a container for all the processed information about the text.\n",
    "text_to_process = \"They are solving a mystery!\"\n",
    "doc_object = nlp_pipeline_pt(text_to_process)\n",
    "\n",
    "# Iterate through each 'token' (word or punctuation mark) in the processed 'Doc' object.\n",
    "# For each token, extract its original text ('token.text') and its Part-of-Speech (POS) tag ('token.pos_').\n",
    "# The POS tag represents the grammatical category of the word (e.g., NOUN, VERB, ADJ, PRON).\n",
    "# The results are collected into a list of tuples, where each tuple is (word, POS_tag).\n",
    "# This provides a quick way to see the POS tagging performed by the spaCy model.\n",
    "pos_tagged_list = [(token.text, token.pos_) for token in doc_object]\n",
    "\n",
    "# The 'pos_tagged_list' would then contain something like:\n",
    "# [('They', 'PRON'), ('are', 'AUX'), ('solving', 'VERB'), ('a', 'DET'), ('mystery', 'NOUN'), ('!', 'PUNCT')]\n",
    "# This output would typically be printed or used for further analysis.\n",
    "print(pos_tagged_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
