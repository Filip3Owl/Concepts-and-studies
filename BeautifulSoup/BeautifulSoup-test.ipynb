{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65a368d9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Introduction to Web Scraping with BeautifulSoup\n",
    "\n",
    "Welcome to this notebook!\n",
    "\n",
    "Here, we'll explore the fascinating world of **Web Scraping** using the **BeautifulSoup** library in Python. Web scraping is a powerful technique for extracting data from websites, transforming unstructured web content into structured, usable information.\n",
    "\n",
    "## What is BeautifulSoup?\n",
    "\n",
    "**BeautifulSoup** is a Python library that makes parsing HTML and XML documents easy. It builds a \"parse tree\" from the web page, allowing you to navigate, search, and modify the content in a simple and intuitive way. Think of it as having a detailed map of a website's structure!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "889b85a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850cd231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an HTTP GET request to the Python.org homepage.\n",
    "# The 'requests.get()' function downloads the content of the specified URL.\n",
    "pages = requests.get('https://www.python.org/')\n",
    "\n",
    "# Parse the raw HTML content obtained from the request using BeautifulSoup.\n",
    "# 'pages.content' provides the raw bytes of the HTML page.\n",
    "# 'html.parser' specifies that Python's built-in HTML parser should be used.\n",
    "# The 'soup' object now contains a parsed representation of the HTML,\n",
    "# which allows you to easily navigate and search its elements.\n",
    "soup = BeautifulSoup(pages.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd96842b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'soup' is already a BeautifulSoup object containing parsed HTML:\n",
    "# (from the previous example: soup = BeautifulSoup(pages.content, 'html.parser'))\n",
    "\n",
    "# Use the find_all() method of the BeautifulSoup object to find all occurrences of a specific HTML tag.\n",
    "# 'a' is the HTML tag for hyperlinks (anchor tags).\n",
    "# This line finds every <a> tag present in the 'soup' (the entire parsed HTML document).\n",
    "# The result, 'links', will be a list of BeautifulSoup Tag objects,\n",
    "# each representing an <a> tag found in the HTML.\n",
    "links = soup.find_all('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4f46735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "https://www.python.org/psf/\n",
      "https://docs.python.org\n",
      "https://pypi.org/\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "https://psfmember.org/civicrm/contribute/transact?reset=1&id=2\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "https://www.linkedin.com/company/python-software-foundation/\n",
      "https://fosstodon.org/@ThePSF\n",
      "No valid URL found\n",
      "https://twitter.com/ThePSF\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "http://brochure.getpython.info/\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "https://docs.python.org/3/license.html\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "https://wiki.python.org/moin/BeginnersGuide\n",
      "https://devguide.python.org/\n",
      "https://docs.python.org/faq/\n",
      "http://wiki.python.org/moin/Languages\n",
      "https://peps.python.org\n",
      "https://wiki.python.org/moin/PythonBooks\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "https://wiki.python.org/moin/\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "http://pyfound.blogspot.com/\n",
      "http://pycon.blogspot.com/\n",
      "http://planetpython.org/\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "https://wiki.python.org/moin/PythonEventsCalendar#Submitting_an_Event\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "http://docs.python.org/3/tutorial/introduction.html#using-python-as-a-calculator\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "https://docs.python.org\n",
      "No valid URL found\n",
      "https://blog.python.org\n",
      "https://pythoninsider.blogspot.com/2025/06/python-3134-31211-31113-31018-and-3923.html\n",
      "https://pythoninsider.blogspot.com/2025/05/python-3140-beta-2-is-here.html\n",
      "https://pythoninsider.blogspot.com/2025/05/python-3140-beta-1-is-here.html\n",
      "https://pyfound.blogspot.com/2025/05/announcing-python-software-foundation.html\n",
      "https://pyfound.blogspot.com/2025/05/a-thank-you-to-oregon-state-university.html\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "http://www.djangoproject.com/\n",
      "http://www.pylonsproject.org/\n",
      "http://bottlepy.org\n",
      "http://tornadoweb.org\n",
      "http://flask.pocoo.org/\n",
      "http://www.web2py.com/\n",
      "http://wiki.python.org/moin/TkInter\n",
      "https://wiki.gnome.org/Projects/PyGObject\n",
      "http://www.riverbankcomputing.co.uk/software/pyqt/intro\n",
      "https://wiki.qt.io/PySide\n",
      "https://kivy.org/\n",
      "http://www.wxpython.org/\n",
      "https://dearpygui.readthedocs.io/en/latest/\n",
      "http://www.scipy.org\n",
      "http://pandas.pydata.org/\n",
      "http://ipython.org\n",
      "http://buildbot.net/\n",
      "http://trac.edgewall.org/\n",
      "http://roundup.sourceforge.net/\n",
      "http://www.ansible.com\n",
      "https://saltproject.io\n",
      "https://www.openstack.org\n",
      "https://xon.sh\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "http://brochure.getpython.info/\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "https://docs.python.org/3/license.html\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "https://wiki.python.org/moin/BeginnersGuide\n",
      "https://devguide.python.org/\n",
      "https://docs.python.org/faq/\n",
      "http://wiki.python.org/moin/Languages\n",
      "https://peps.python.org\n",
      "https://wiki.python.org/moin/PythonBooks\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "https://wiki.python.org/moin/\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "http://pyfound.blogspot.com/\n",
      "http://pycon.blogspot.com/\n",
      "http://planetpython.org/\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "https://wiki.python.org/moin/PythonEventsCalendar#Submitting_an_Event\n",
      "No valid URL found\n",
      "https://devguide.python.org/\n",
      "https://github.com/python/cpython/issues\n",
      "https://mail.python.org/mailman/listinfo/python-dev\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "https://github.com/python/pythondotorg/issues\n",
      "https://status.python.org/\n",
      "No valid URL found\n",
      "No valid URL found\n",
      "https://policies.python.org/python.org/Privacy-Notice/\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'links' is a list of BeautifulSoup Tag objects, where each Tag represents an <a> (anchor) element.\n",
    "# (from the previous example: links = soup.find_all('a'))\n",
    "\n",
    "# Iterate through each 'link' (which is an <a> tag object) in the 'links' list.\n",
    "for link in links:\n",
    "    # Check two conditions for each link:\n",
    "    # 1. 'link.get('href')': This retrieves the value of the 'href' attribute from the <a> tag.\n",
    "    #    The 'href' attribute contains the URL that the hyperlink points to.\n",
    "    #    '.get()' is used because it safely returns None if the 'href' attribute doesn't exist,\n",
    "    #    preventing a KeyError.\n",
    "    # 2. 'and 'http' in link.get('href')': If 'href' exists (is not None), this checks if the string 'http'\n",
    "    #    is present within the 'href' value. This is a simple way to filter for absolute URLs\n",
    "    #    (i.e., those starting with 'http://' or 'https://').\n",
    "    if link.get('href') and 'http' in link.get('href'):\n",
    "        # If both conditions are true (the 'href' attribute exists and contains 'http'),\n",
    "        # print the value of the 'href' attribute, which is the full URL.\n",
    "        print(link.get('href'))\n",
    "    else:\n",
    "        # If either condition is false (no 'href' or no 'http' in 'href'),\n",
    "        # it means the link is not an external, absolute URL in the format we're looking for.\n",
    "        # In this case, print a message indicating that no valid URL was found for this specific link.\n",
    "        print(\"No valid URL found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc7cadcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.python.org/'\n",
    "# Make an HTTP GET request to the specified URL.\n",
    "data  = requests.get(url).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd504e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<img alt=\"pythonâ„¢\" class=\"python-logo\" src=\"/static/img/python-logo.png\"/>\n",
      "/static/img/python-logo.png\n"
     ]
    }
   ],
   "source": [
    "for link in soup.find_all('img'):\n",
    "    print(link)\n",
    "    print(link.get('src'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
